{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('TwitterHate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = data['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_lower = [tweet.lower() for tweet in tweets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_lower[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##removing url, user handles, #\n",
    "\n",
    "tweet_user_rem = [re.sub(\"@\\w+\\s\",\"\", tweet) for tweet in tweet_lower]\n",
    "tweet_hash_rem = [re.sub(\"#+\",\"\", tweet) for tweet in tweet_user_rem]\n",
    "tweet_url_rem = [re.sub(\"\\w://\\S\",\"\", tweet) for tweet in tweet_hash_rem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"thanks for lyft credit i can't use cause they don't offer wheelchair vans in pdx.    disapointed getthanked\",\n",
       " '  bihday your majesty']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_url_rem[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = [token.tokenize(tweet) for tweet in tweet_url_rem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['when',\n",
       "  'a',\n",
       "  'father',\n",
       "  'is',\n",
       "  'dysfunctional',\n",
       "  'and',\n",
       "  'is',\n",
       "  'so',\n",
       "  'selfish',\n",
       "  'he',\n",
       "  'drags',\n",
       "  'his',\n",
       "  'kids',\n",
       "  'into',\n",
       "  'his',\n",
       "  'dysfunction',\n",
       "  '.',\n",
       "  'run'],\n",
       " ['thanks',\n",
       "  'for',\n",
       "  'lyft',\n",
       "  'credit',\n",
       "  'i',\n",
       "  \"can't\",\n",
       "  'use',\n",
       "  'cause',\n",
       "  'they',\n",
       "  \"don't\",\n",
       "  'offer',\n",
       "  'wheelchair',\n",
       "  'vans',\n",
       "  'in',\n",
       "  'pdx',\n",
       "  '.',\n",
       "  'disapointed',\n",
       "  'getthanked']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords and punctuation\n",
    "stop_words = stopwords.words('english')\n",
    "punct = list(punctuation)\n",
    "stop_context = ['rt', 'amp', '...', '```', ]\n",
    "stop_terms = stop_words + punct + stop_context\n",
    "words_clean1 = [[word for word in tokens if word not in stop_terms] for tokens in tokenized_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run'],\n",
       " ['thanks',\n",
       "  'lyft',\n",
       "  'credit',\n",
       "  \"can't\",\n",
       "  'use',\n",
       "  'cause',\n",
       "  'offer',\n",
       "  'wheelchair',\n",
       "  'vans',\n",
       "  'pdx',\n",
       "  'disapointed',\n",
       "  'getthanked']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_clean1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra cleanup by removing terms with a length of 1.\n",
    "words_clean = [[word for word in tokens if len(word) > 1] for tokens in words_clean1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run'],\n",
       " ['thanks',\n",
       "  'lyft',\n",
       "  'credit',\n",
       "  \"can't\",\n",
       "  'use',\n",
       "  'cause',\n",
       "  'offer',\n",
       "  'wheelchair',\n",
       "  'vans',\n",
       "  'pdx',\n",
       "  'disapointed',\n",
       "  'getthanked']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_clean[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2680),\n",
       " ('day', 2271),\n",
       " ('happy', 1683),\n",
       " ('time', 1128),\n",
       " ('life', 1103),\n",
       " ('like', 1097),\n",
       " (\"i'm\", 1018),\n",
       " ('today', 1008),\n",
       " ('new', 988),\n",
       " ('positive', 929)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check out the top terms in the tweets:\n",
    "#First, get all the tokenized terms into one large list.\n",
    "word_list = []\n",
    "for words in words_clean:\n",
    "    word_list.extend(words)\n",
    "word_list[0:2]\n",
    "#Use the counter and find the 10 most common terms.\n",
    "counter = Counter(word_list)\n",
    "counter.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data formatting for predictive modeling:\n",
    "#Join the tokens back to form strings. This will be required for the vectorizers.\n",
    "cleaned_tweets = [\" \".join(tweets) for tweets in words_clean]\n",
    "#Assign x and y.\n",
    "X = cleaned_tweets\n",
    "y = data['label'].tolist()\n",
    "#Perform train_test_split using sklearn.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21414 10548\n",
      "vector dimensions X.train : (21414, 5000) X.test : (10548, 5000)\n"
     ]
    }
   ],
   "source": [
    "#use TF-IDF values for the terms as a feature to get into a vector space model.\n",
    "#Instantiate with a maximum of 5000 terms in your vocabulary.\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "print(len(X_train), len(X_test))\n",
    "#Fit and apply on the train set.\n",
    "X_train_vector = vectorizer.fit_transform(X_train)\n",
    "#Apply on the test set.\n",
    "X_test_vector = vectorizer.fit_transform(X_test)\n",
    "print('vector dimensions X.train :', X_train_vector.shape, 'X.test :', X_test_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Model building: Ordinary Logistic Regression\n",
    "#Fit into  the train data.\n",
    "logreg = LogisticRegression()\n",
    "logregmodel = logreg.fit(X_train_vector, y_train)\n",
    "#Make predictions for the train and the test set.\n",
    "pred = logregmodel.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.927284793325749\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      9806\n",
      "           1       0.00      0.00      0.00       742\n",
      "\n",
      "    accuracy                           0.93     10548\n",
      "   macro avg       0.46      0.50      0.48     10548\n",
      "weighted avg       0.86      0.93      0.89     10548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fairly good results, we can also go for class imbalence adjustment\n",
    "logreg_bal = LogisticRegression(class_weight = 'balanced')\n",
    "logregmodel_bal = logreg_bal.fit(X_train_vector, y_train)\n",
    "#Make predictions for the train and the test set.\n",
    "pred = logregmodel_bal.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8310580204778157\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      9806\n",
      "           1       0.05      0.08      0.06       742\n",
      "\n",
      "    accuracy                           0.83     10548\n",
      "   macro avg       0.49      0.48      0.48     10548\n",
      "weighted avg       0.87      0.83      0.85     10548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not good results when using the imbalence adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization and Hyperparameter tuning:\n",
    "\n",
    "#Import GridSearch and StratifiedKFold because of class imbalance.\n",
    "#Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters.\n",
    "#Use a balanced class weight while instantiating the logistic regression\n",
    "\n",
    "param_grid = {'C': [0.01,0.1,1,10,100], 'penalty': [\"l1\",\"l2\"]}\n",
    "logreg_classifier = LogisticRegression(class_weight = 'balanced')\n",
    "grid_search = GridSearchCV(estimator = logreg_classifier, param_grid = param_grid, cv = StratifiedKFold(4),\n",
    "                           n_jobs=-1, scoring = 'recall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_vector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = grid_search.best_estimator_.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score 0.8310580204778157\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy_score', accuracy_score(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      9806\n",
      "           1       0.05      0.08      0.06       742\n",
      "\n",
      "    accuracy                           0.83     10548\n",
      "   macro avg       0.49      0.48      0.48     10548\n",
      "weighted avg       0.87      0.83      0.85     10548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
